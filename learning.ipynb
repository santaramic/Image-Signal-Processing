{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Untitled1.ipynb","provenance":[],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"KSqkCurjx42v","executionInfo":{"status":"ok","timestamp":1644307609038,"user_tz":-540,"elapsed":620,"user":{"displayName":"변성주","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCC1sIS4EqJv_etS6a_3KLkFhkQbJKk0cRW15Gbw=s64","userId":"02743720240721246672"}},"outputId":"7f6949c5-3b61-47b0-e9b4-13309499e2f1","colab":{"base_uri":"https://localhost:8080/"}},"source":["!cp \"/content/drive/MyDrive/2021_2_class/Cat_and_dog.tar\" \"/content/data/Cat_and_dog.tar\""],"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["cp: cannot stat '/content/drive/MyDrive/2021_2_class/Cat_and_dog.tar': No such file or directory\n"]}]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_bUPDxgCXj2q","executionInfo":{"status":"ok","timestamp":1644307585393,"user_tz":-540,"elapsed":21297,"user":{"displayName":"변성주","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCC1sIS4EqJv_etS6a_3KLkFhkQbJKk0cRW15Gbw=s64","userId":"02743720240721246672"}},"outputId":"8d98ec46-6901-496e-c482-a24d1fe7af77"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Usb1S70aMg0Q","executionInfo":{"status":"ok","timestamp":1644307805519,"user_tz":-540,"elapsed":429,"user":{"displayName":"변성주","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCC1sIS4EqJv_etS6a_3KLkFhkQbJKk0cRW15Gbw=s64","userId":"02743720240721246672"}},"outputId":"18c687cb-5838-4a90-d520-c7bf784270fe"},"source":["from google.colab import drive\n","drive._mount('/content/drive')"],"execution_count":6,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}]},{"cell_type":"code","metadata":{"id":"ycOs4THB0bM3","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1644307811495,"user_tz":-540,"elapsed":659,"user":{"displayName":"변성주","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCC1sIS4EqJv_etS6a_3KLkFhkQbJKk0cRW15Gbw=s64","userId":"02743720240721246672"}},"outputId":"b601e9a3-88e6-4532-ba4b-e0c1135d1e6c"},"source":["!tar -xvf \"/content/data/Cat_and_dog.tar\""],"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["tar: /content/data/Cat_and_dog.tar: Cannot open: No such file or directory\n","tar: Error is not recoverable: exiting now\n"]}]},{"cell_type":"code","metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"JRTHP65D0rIy","executionInfo":{"status":"ok","timestamp":1636811252984,"user_tz":-540,"elapsed":492020,"user":{"displayName":"변성주","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14GgCC1sIS4EqJv_etS6a_3KLkFhkQbJKk0cRW15Gbw=s64","userId":"02743720240721246672"}},"outputId":"dbf9140f-7fc9-47a4-b2f6-bafcb50d7fef"},"source":["# -*- coding:utf-8 -*-\n","from random import shuffle\n","\n","import tensorflow as tf\n","import numpy as np\n","import easydict # 저는 이 기능을 전역변수로서 사용하려고 합니다.\n","import matplotlib.pyplot as plt\n","import os\n","\n","FLAGS = easydict.EasyDict({\"img_size\": 224,\n","                           \n","                           \"tr_txt_path\": \"/content/train.txt\",\n","\n","                           \"tr_img_path\": \"/content/Cat_Dog_500_train/\",\n","\n","                           \"val_txt_path\": \"/content/val.txt\",\n","\n","                           \"val_img_path\": \"/content/Cat_Dog_100_val/\",\n","\n","                           \"te_txt_path\": \"/content/test.txt\",\n","\n","                           \"te_img_path\": \"/content/Cat_Dog_200_test/\",\n","                           \n","                           \"batch_size\": 24,\n","\n","                           \"pre_checkpoint\": False, # 학습이 멈추어 이어서 시작해야 할때, 혹은 테스트를 진행할 때\n","\n","                           \"pre_checkpoint_path\": \"\",   # 학습된 weight가 저장된 경로\n","\n","                           \"save_checkpoint\": \"/content/drive/MyDrive/2021_2_class/checkpoint\",\n","                           \n","                           \"epochs\": 10,\n","                           \n","                           \"lr\": 0.001})\n","\n","optim = tf.keras.optimizers.Adam(FLAGS.lr)\n","\n","def tr_input(img_list, lab_list):\n","\n","    img = tf.io.read_file(img_list)\n","    img = tf.image.decode_jpeg(img, 3)\n","    img = tf.image.resize(img, [FLAGS.img_size, FLAGS.img_size]) / 255.\n","\n","    lab = lab_list\n","\n","    return img, lab\n","\n","def cal_loss(model, images, labels):\n","\n","    with tf.GradientTape() as tape:\n","\n","        logits = model(images, True)\n","\n","        loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)(labels, logits)\n","\n","    grads = tape.gradient(loss, model.trainable_variables)\n","    # 첫번 째 conv 에서의 grads의 모양은 ==> [7, 7, 3, 64] ==> 7x7x3x64\n","    optim.apply_gradients(zip(grads, model.trainable_variables))\n","    # updataed weight = previou weight - (lr x grads)\n","    # a = [1,2,3], b = [4,5,6] ==> a와 b를 zip하면 ==> [[1,4], [2,5], [3,6]]\n","\n","\n","    return loss\n","\n","def main():\n","    \n","    # 1. 모델 정의\n","    model = tf.keras.applications.VGG16(include_top=False, input_shape=(FLAGS.img_size, FLAGS.img_size, 3))\n","    x = model.output    # [B, 7, 7, 512]\n","    h = tf.keras.layers.Flatten()(x)\n","    h = tf.keras.layers.Dense(1024)(h)\n","    h = tf.keras.layers.ReLU()(h)\n","    h = tf.keras.layers.Dense(1024)(h)\n","    h = tf.keras.layers.Dense(1)(h)\n","    model = tf.keras.Model(inputs= model.input, outputs=h)\n","\n","    model.summary()\n","\n","    if FLAGS.pre_checkpoint:\n","        ckpt = tf.train.Checkpoint(model=model, optim=optim)\n","        ckpt_manager = tf.train.CheckpointManager(ckpt, FLAGS.pre_checkpoint_path, 5)\n","\n","        if ckpt_manger.latest_checkpoint:\n","            ckpt.restore(ckpt_manger.latest_checkpoint)\n","            print(\"Restored!!!!!\")\n","\n","    # 2. 입력 정의 (학습, 테스트, 확인용)\n","    tr_img_data = np.loadtxt(FLAGS.tr_txt_path, dtype=\"<U100\", skiprows=0, usecols=0)\n","    tr_img_data = [FLAGS.tr_img_path + data for data in tr_img_data]\n","    tr_img_data = np.array(tr_img_data)\n","    tr_lab_data = np.loadtxt(FLAGS.tr_txt_path, dtype=np.int32, skiprows=0, usecols=1)\n","\n","    val_img_data = np.loadtxt(FLAGS.val_txt_path, dtype=\"<U100\", skiprows=0, usecols=0)\n","    val_img_data = [FLAGS.val_img_path + data for data in val_img_data]\n","    val_img_data = np.array(val_img_data)\n","    val_lab_data = np.loadtxt(FLAGS.val_txt_path, dtype=np.int32, skiprows=0, usecols=1)\n","\n","    te_img_data = np.loadtxt(FLAGS.te_txt_path, dtype=\"<U100\", skiprows=0, usecols=0)\n","    te_img_data = [FLAGS.te_img_path + data for data in te_img_data]\n","    te_img_data = np.array(te_img_data)\n","    te_lab_data = np.loadtxt(FLAGS.te_txt_path, dtype=np.int32, skiprows=0, usecols=1)\n","\n","    count = 0\n","    for epoch in range(FLAGS.epochs):\n","\n","        tr_generator = tf.data.Dataset.from_tensor_slices((tr_img_data, tr_lab_data))\n","        tr_generator = tr_generator.shuffle(len(tr_img_data))\n","        tr_generator = tr_generator.map(tr_input)\n","        tr_generator = tr_generator.batch(FLAGS.batch_size)\n","        tr_generator = tr_generator.prefetch(tf.data.experimental.AUTOTUNE)\n","\n","        tr_iter = iter(tr_generator)\n","        tr_idx = len(tr_img_data) // FLAGS.batch_size\n","        for step in range(tr_idx):\n","            batch_images, batch_labels = next(tr_iter)\n","\n","            loss = cal_loss(model, batch_images, batch_labels)\n","\n","            if count % 10 == 0:\n","                print(\"Epoch: {} [{}/{}] loss = {}\".format(epoch, step + 1, tr_idx, loss))\n","            \n","\n","            if count % 200 == 0:\n","                num = str(int(count) // 200)\n","                model_dir = \"%s/%s\" % (FLAGS.save_checkpoint, num)\n","\n","                ckpt = tf.train.Checkpoint(model=model, optim=optim)\n","                if not os.path.isdir(model_dir):\n","                    os.makedirs(model_dir)\n","                    print(\"Made {} files to save weights\".format(num))\n","\n","                ckpt_dir = model_dir + \"/\" + \"fix_vgg_16_model_{}.ckpt\".format(count)\n","                ckpt.save(ckpt_dir)\n","\n","\n","\n","            count += 1\n","\n","\n","\n","\n","\n","    # Train, Test, Validation\n"," \n","if __name__ == \"__main__\":\n","    main()\n"],"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Model: \"model_2\"\n","_________________________________________________________________\n"," Layer (type)                Output Shape              Param #   \n","=================================================================\n"," input_3 (InputLayer)        [(None, 224, 224, 3)]     0         \n","                                                                 \n"," block1_conv1 (Conv2D)       (None, 224, 224, 64)      1792      \n","                                                                 \n"," block1_conv2 (Conv2D)       (None, 224, 224, 64)      36928     \n","                                                                 \n"," block1_pool (MaxPooling2D)  (None, 112, 112, 64)      0         \n","                                                                 \n"," block2_conv1 (Conv2D)       (None, 112, 112, 128)     73856     \n","                                                                 \n"," block2_conv2 (Conv2D)       (None, 112, 112, 128)     147584    \n","                                                                 \n"," block2_pool (MaxPooling2D)  (None, 56, 56, 128)       0         \n","                                                                 \n"," block3_conv1 (Conv2D)       (None, 56, 56, 256)       295168    \n","                                                                 \n"," block3_conv2 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_conv3 (Conv2D)       (None, 56, 56, 256)       590080    \n","                                                                 \n"," block3_pool (MaxPooling2D)  (None, 28, 28, 256)       0         \n","                                                                 \n"," block4_conv1 (Conv2D)       (None, 28, 28, 512)       1180160   \n","                                                                 \n"," block4_conv2 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_conv3 (Conv2D)       (None, 28, 28, 512)       2359808   \n","                                                                 \n"," block4_pool (MaxPooling2D)  (None, 14, 14, 512)       0         \n","                                                                 \n"," block5_conv1 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv2 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_conv3 (Conv2D)       (None, 14, 14, 512)       2359808   \n","                                                                 \n"," block5_pool (MaxPooling2D)  (None, 7, 7, 512)         0         \n","                                                                 \n"," flatten_2 (Flatten)         (None, 25088)             0         \n","                                                                 \n"," dense_6 (Dense)             (None, 1024)              25691136  \n","                                                                 \n"," re_lu_2 (ReLU)              (None, 1024)              0         \n","                                                                 \n"," dense_7 (Dense)             (None, 1024)              1049600   \n","                                                                 \n"," dense_8 (Dense)             (None, 1)                 1025      \n","                                                                 \n","=================================================================\n","Total params: 41,456,449\n","Trainable params: 41,456,449\n","Non-trainable params: 0\n","_________________________________________________________________\n","Epoch: 0 [1/41] loss = 0.7578914165496826\n","Epoch: 0 [11/41] loss = 1.9970555305480957\n","Epoch: 0 [21/41] loss = 0.6858832240104675\n","Epoch: 0 [31/41] loss = 0.6984705924987793\n","Epoch: 0 [41/41] loss = 0.790132462978363\n","Epoch: 1 [10/41] loss = 0.6800658106803894\n","Epoch: 1 [20/41] loss = 0.6544758677482605\n","Epoch: 1 [30/41] loss = 0.6571474671363831\n","Epoch: 1 [40/41] loss = 0.6932084560394287\n","Epoch: 2 [9/41] loss = 0.6942588686943054\n","Epoch: 2 [19/41] loss = 0.6897203326225281\n","Epoch: 2 [29/41] loss = 0.693278968334198\n","Epoch: 2 [39/41] loss = 0.693516731262207\n","Epoch: 3 [8/41] loss = 0.6930853724479675\n","Epoch: 3 [18/41] loss = 0.6908175349235535\n","Epoch: 3 [28/41] loss = 0.6932423710823059\n","Epoch: 3 [38/41] loss = 0.6966134905815125\n","Epoch: 4 [7/41] loss = 0.693922221660614\n","Epoch: 4 [17/41] loss = 0.6960897445678711\n","Epoch: 4 [27/41] loss = 0.6914361119270325\n","Epoch: 4 [37/41] loss = 0.6925954818725586\n","Epoch: 5 [6/41] loss = 0.6965776085853577\n","Epoch: 5 [16/41] loss = 0.6986357569694519\n","Epoch: 5 [26/41] loss = 0.7001288533210754\n","Epoch: 5 [36/41] loss = 0.6947646141052246\n","Epoch: 6 [5/41] loss = 0.6939196586608887\n","Epoch: 6 [15/41] loss = 0.6860468983650208\n","Epoch: 6 [25/41] loss = 0.693798303604126\n","Epoch: 6 [35/41] loss = 0.6931471824645996\n","Epoch: 7 [4/41] loss = 0.6934525966644287\n","Epoch: 7 [14/41] loss = 0.6864469647407532\n","Epoch: 7 [24/41] loss = 0.6933725476264954\n","Epoch: 7 [34/41] loss = 0.693686306476593\n","Epoch: 8 [3/41] loss = 0.6944258213043213\n","Epoch: 8 [13/41] loss = 0.6945521235466003\n","Epoch: 8 [23/41] loss = 0.6935809254646301\n","Epoch: 8 [33/41] loss = 0.6911333203315735\n","Epoch: 9 [2/41] loss = 0.693554162979126\n","Epoch: 9 [12/41] loss = 0.6938269734382629\n","Epoch: 9 [22/41] loss = 0.69380784034729\n","Epoch: 9 [32/41] loss = 0.6950142979621887\n"]}]}]}